{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_root = \"..\"\n",
    "save_data_root = f\"{repo_root}/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip {save_data_root}/archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchaudio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import librosa\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for path in tqdm(Path(f\"{save_data_root}/TESS Toronto emotional speech set data\").glob(\"**/*.wav\")):\n",
    "    name = str(path).split('/')[-1].split('.')[0]\n",
    "    label = str(path).split('/')[-2]\n",
    "    \n",
    "    try:\n",
    "        # There are some broken files\n",
    "        s = torchaudio.load(path)\n",
    "        data.append({\n",
    "            \"name\": name,\n",
    "            \"path\": path,\n",
    "            \"emotion\": label\n",
    "        })\n",
    "    except Exception as e:\n",
    "        # print(str(path), e)\n",
    "        pass\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter broken and non-existed paths\n",
    "\n",
    "print(f\"Step 0: {len(df)}\")\n",
    "\n",
    "df[\"status\"] = df[\"path\"].apply(lambda path: True if os.path.exists(path) else None)\n",
    "df = df.dropna(subset=[\"path\"])\n",
    "df = df.drop(\"status\", 1)\n",
    "print(f\"Step 1: {len(df)}\")\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Labels: \", df[\"emotion\"].unique())\n",
    "print()\n",
    "df.groupby(\"emotion\").count()[[\"path\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display random sample\n",
    "idx = np.random.randint(0, len(df))\n",
    "sample = df.iloc[idx]\n",
    "path = sample[\"path\"]\n",
    "label = sample[\"emotion\"]\n",
    "\n",
    "\n",
    "print(f\"ID Location: {idx}\")\n",
    "print(f\"      Label: {label}\")\n",
    "print()\n",
    "\n",
    "speech, sr = torchaudio.load(path)\n",
    "speech = speech[0].numpy().squeeze()\n",
    "speech = librosa.resample(np.asarray(speech), sr, 16_000)\n",
    "ipd.Audio(data=np.asarray(speech), autoplay=True, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test spliting\n",
    "\n",
    "save_path = \"/content/TESS Toronto emotional speech set data\"\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=101, stratify=df[\"emotion\"])\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "train_df.to_csv(f\"{save_data_root}/train.csv\", sep=\"\\t\", encoding=\"utf-8\", index=False)\n",
    "test_df.to_csv(f\"{save_data_root}/test.csv\", sep=\"\\t\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
